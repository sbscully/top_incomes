#!/usr/bin/env perl

use strict;
use warnings;

use feature 'say';

use JSON::XS;
use File::Slurp;
use Data::Dumper;

sub inspect { say Dumper @_ }

sub second { $_[1] }

sub flatten { map { ref $_ eq 'ARRAY' ? flatten(@$_) : $_ } @_ }

sub compose {
  my $g = pop;
  my $f = pop;
  my @subs = @_;

  if ( @subs ) {
    sub { $g->( compose(@subs, $f)->(@_) ) }
  }
  else {
    sub { $g->($f->(@_)) };
  }
}

sub pipeline (+@) {
  my ($args, @subs) = @_;

  @subs = map { ref $_ eq 'CODE' ? $_ : \&$_ } @subs;

  compose(@subs)->(@$args)
}

sub transpose_table {
  my $data = \@_;
  my $inverted = [];

  foreach my $i ( (0..scalar(@$data)-1) ) {
    foreach my $j ( (0..scalar(@{ $data->[1] })-1) ) {
      $inverted->[$j] //= [];
      $inverted->[$j][$i] = $data->[$i][$j];
    }
  }

  return @$inverted;
}

sub zip { my ($a, $b) = @_; map { [ $a->[$_], $b->[$_] ] } (0..scalar(@$a)-1) }

sub pairs_to_hashref { my %hash = flatten @_; \%hash }

sub compact_pairs { grep { defined $_->[1] } @_ }

sub deref {
  my $ref = ref $_[0];

  if    ( $ref eq 'ARRAY' ) { @{ $_[0] }; }
  elsif ( $ref eq 'HASH' )  { %{ $_[0] }; }
  else                      { @_; }
}

sub fetch { my ($key) = @_; sub { my %hash = @_; $hash{$key} } }

# Skip the specified number of rows of a table and return the rest
sub skip_rows { my $skip = shift; sub { @_[$skip..scalar(@_)-1] } }

# Takes the name of a JSON file, extracts and decodes the data
sub parse_json { pipeline @_, qw(read_file decode_json deref) }

# Takes the output of Spreadsheet::Read and extracts the raw spreadsheet table
sub extract_table { pipeline @_, 'second', 'deref', fetch('cell'), 'deref' }

# Takes the Spreadsheet::Read output of the Capital in the
# 21st Century (Pikkety) xlsx file and extract the relevant data
sub parse_top_incomes_data { pipeline @_, 'extract_table', 'transpose_table', skip_rows(2) }

# Takes table headers and a row, and turns them into a compact[1] hashref
# with the table headers as keys
#
# [1] a hashref where keys which have undefined values have been removed
sub row_to_hashref { pipeline @_, qw(zip compact_pairs pairs_to_hashref) }

sub process_top_incomes {
  my @table = pipeline @_, qw(parse_json parse_top_incomes_data);
  my $headers = shift @table;

  map { row_to_hashref($headers, $_) } @table
}

{
  my $in = 'data/converted.json';
  my $out = 'data/transformed.json';

  if (-f $out) { unlink $out }

  write_file $out, JSON::XS->new->utf8->pretty(1)->encode([process_top_incomes($in)]);
}