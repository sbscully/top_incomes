#!/usr/bin/env perl

use strict;
use warnings;

use feature 'say';

use JSON::XS;
use File::Slurp;
use Data::Dumper;

sub first { $_[0] }

sub second { $_[1] }

sub rest { @_[1..scalar(@_)-1] }

sub final { $_[-1] }

sub flatten { map { ref $_ eq 'ARRAY' ? flatten(@$_) : $_ } @_ }

sub compose {
  my $g = pop;
  my $f = pop;
  my @subs = @_;

  if ( @subs ) {
    sub { $g->( compose(@subs, $f)->(@_) ) }
  }
  else {
    sub { $g->($f->(@_)) };
  }
}

sub pipeline (+@) {
  my $args = shift;
  my @subs = @_;

  @subs = map { ref $_ eq 'CODE' ? $_ : \&$_ } @subs;

  compose(@subs)->(@$args)
}

sub curry {
  my ($sub, @args) = @_;

  sub { $sub->(@args, @_) }
}

sub transpose_table {
  my $data = \@_;
  my $inverted = [];

  foreach my $i ( (0..scalar(@$data)-1) ) {
    foreach my $j ( (0..scalar(@{ $data->[1] })-1) ) {
      $inverted->[$j] //= [];
      $inverted->[$j][$i] = $data->[$i][$j];
    }
  }

  return @$inverted;
}

sub zip { my ($a, $b) = @_; map { [ $a->[$_], $b->[$_] ] } (0..scalar(@$a)-1) }

sub hashref { my %hash = flatten @_; \%hash }

sub arrayref { [ @_ ] }

sub compact { grep { defined $_->[1] } @_ }

sub deref {
  my $ref = ref $_[0];

  if    ( $ref eq 'ARRAY' ) { @{ $_[0] }; }
  elsif ( $ref eq 'HASH' )  { %{ $_[0] }; }
  else                      { @_; }
}

sub fetch { my ($key) = @_; sub { my %hash = @_; $hash{$key} } }

# Skip the specified number of rows of a table and return the rest
sub skip_rows { my $skip = shift; sub { @_[$skip..scalar(@_)-1] } }

# Takes the name of a JSON file, extracts and decodes the data
sub extract_json { pipeline @_, qw(read_file decode_json deref) }

# Takes the output of Spreadsheet::Read and extracts the raw spreadsheet table
sub extract_table { pipeline @_, 'second', 'deref', fetch('cell'), 'deref' }

# Takes the Spreadsheet::Read output of the Capital in the
# 21st Century (Pikkety) xlsx file and extract the relevant data
sub extract_top_incomes_data { pipeline @_, 'extract_table', 'transpose_table', skip_rows(2) }

# Takes the table headers and a row, and turns that into a hashref
# with undefined values removed
sub process_row { pipeline @_, qw(zip compact hashref) }

# Takes the headers and data for a table and turns the rows into
# an array of hashrefs
sub process_table { my ($headers, $table) = @_; map { process_row($headers, $_) } @$table }

sub process_top_incomes {
  my @data = pipeline @_, qw(extract_json extract_top_incomes_data);

  my @headers = deref first @data;
  my @table = rest @data;

  process_table(\@headers, \@table);
}

say Dumper final process_top_incomes 'data/top_incomes.json';