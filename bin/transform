#!/usr/bin/env perl

use strict;
use warnings;

use feature 'say';
use Data::Dumper;
sub inspect { say Dumper @_ }

use JSON::XS;
use File::Slurp;

sub compose {
  my $g = pop;
  my $f = pop;
  my @subs = @_;

  if ( @subs ) {
    sub { $g->( compose(@subs, $f)->(@_) ) }
  }
  else {
    sub { $g->($f->(@_)) };
  }
}

sub pipeline (+@) {
  my ($args, @subs) = @_;

  @subs = map { ref $_ eq 'CODE' ? $_ : \&$_ } @subs;

  compose(@subs)->(@$args)
}

sub transpose {
  my $data = \@_;
  my $transposed = [];

  foreach my $i ( (0..scalar(@$data)-1) ) {
    foreach my $j ( (0..scalar(@{ $data->[1] })-1) ) {
      $transposed->[$j] //= [];
      $transposed->[$j][$i] = $data->[$i][$j];
    }
  }

  return @$transposed;
}

sub zip { my ($a, $b) = @_; map { [ $a->[$_], $b->[$_] ] } (0..scalar(@$a)-1) }

sub compact_pairs { grep { defined $_->[0] && defined $_->[1] } @_ }

sub flatten { map { ref $_ eq 'ARRAY' ? flatten(@$_) : $_ } @_ }

sub hashref { my %hash = @_; \%hash }

sub deref {
  my $ref = ref $_[0];
  my $single = scalar(@_) eq 1;

  if    ( $ref eq 'ARRAY' && $single ) { @{ $_[0] }; }
  elsif ( $ref eq 'HASH' && $single )  { %{ $_[0] }; }
  else                                 { @_; }
}

sub fetch { my ($key) = @_; sub { my %hash = deref @_; deref $hash{$key} } }

sub at { my ($index) = @_; sub { my @array = deref @_; deref $array[$index] } }

sub process_json (&@) {
  my $sub = shift;
  pipeline @_, 'decode_json', $sub, 'pretty_encode_json'
}

sub pretty_encode_json { JSON::XS->new->utf8->pretty(1)->encode(@_) }

# Sample output row:
#   {
#      "Number of tax units-married couples &amp; single adults" : "22127.693",
#      "Income control" : "1682.08332",
#      "Price index" : "0.0101303",
#      "Average income per tax unit-married couples &amp; single adults" : "7503.9",
#      "Top 0.05-0.01% income share-married couples &amp; single adults" : "4.18",
#      "Year" : "1908.0",
#      "Country" : "United Kingdom",
#      "Top 0.05% income share-married couples &amp; single adults" : "8.22",
#      "Top 0.01% average income-married couples &amp; single adults" : "3031574.98",
#      "Top 0.01% income share-married couples &amp; single adults" : "4.04"
#   }

{
  my $in = 'data/converted.json';
  my $out = 'data/transformed.json';

  if (-f $out) { unlink $out }

  my $json = process_json { [ transform_top_incomes(@_) ] } read_file($in);
  write_file($out, $json);
}

# Take the Spreadsheet::Read output of the "Capital in the
# 21st Century" (Pikkety) xlsx file and extract the relevant data.
#
# The table is transposed so that each row corresponds to a set
# of data points for one country for one year.
#
# The first two rows are skipped because they are just id fields
# that we are not interested in.
#
# Finally the data is transformed from a table into an array of
# hashrefs.
sub transform_top_incomes {
  say "parsing input...";
  my @table = pipeline @_, at(1), fetch('cell'), 'transpose', sub { splice @_, 2 };

  my $count = scalar @table;
  say "transforming $count rows...";

  my $headers = shift @table;
  map { row_to_hashref($headers, $_) } @table;
}

# Take table headers and a row, and turn them into a compact hashref
# with the table headers as keys.
sub row_to_hashref { pipeline @_, qw(zip compact_pairs flatten hashref) }