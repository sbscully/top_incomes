#!/usr/bin/env perl

use strict;
use warnings;

use feature 'say';

use JSON::XS;
use File::Slurp;
use Data::Dumper;

sub inspect { say Dumper @_ }

sub flatten { map { ref $_ eq 'ARRAY' ? flatten(@$_) : $_ } @_ }

sub compose {
  my $g = pop;
  my $f = pop;
  my @subs = @_;

  if ( @subs ) {
    sub { $g->( compose(@subs, $f)->(@_) ) }
  }
  else {
    sub { $g->($f->(@_)) };
  }
}

sub pipeline (+@) {
  my ($args, @subs) = @_;

  @subs = map { ref $_ eq 'CODE' ? $_ : \&$_ } @subs;

  compose(@subs)->(@$args)
}

sub curry { my ($sub, @args) = @_; sub { $sub->(@args, @_) } }

sub transpose {
  my $data = \@_;
  my $inverted = [];

  foreach my $i ( (0..scalar(@$data)-1) ) {
    foreach my $j ( (0..scalar(@{ $data->[1] })-1) ) {
      $inverted->[$j] //= [];
      $inverted->[$j][$i] = $data->[$i][$j];
    }
  }

  return @$inverted;
}

sub zip { my ($a, $b) = @_; map { [ $a->[$_], $b->[$_] ] } (0..scalar(@$a)-1) }

# Takes a hash and returns a copy where the key/value pairs where the
# value was undefined have been removed
sub compact_hash {
  return unless defined $_[0];
  my %hash = @_;

  map { defined($hash{$_}) ? ($_ => $hash{$_}) : () } keys %hash
}

sub hashref { { @_ } }

# Derefere  nce if passed a lone hashref or arrayref
sub deref {
  my $ref = ref $_[0];
  my $single = scalar(@_) eq 1;

  if    ( $ref eq 'ARRAY' && $single ) { @{ $_[0] }; }
  elsif ( $ref eq 'HASH' && $single )  { %{ $_[0] }; }
  else                                 { @_; }
}

# A wrapper around hash key access to allow it to be pipelined
sub fetch { my ($key) = @_; sub { my %hash = deref @_; deref $hash{$key} } }

# A wrapper around array access to allow it to be pipelined
sub at { my ($index) = @_; sub { my @array = deref @_; deref $array[$index] } }

# Skip the specified number of elements of an array and return the rest
sub rest { my $skip = shift // 1; @_[$skip..scalar(@_)-1] }

################################################################

# Takes table headers and a row, and turns them into a compact hashref
# with the table headers as keys.
sub row_to_hashref { pipeline @_, qw(zip flatten compact_hash hashref) }

# Takes the Spreadsheet::Read output of the "Capital in the
# 21st Century" (Pikkety) xlsx file and extracts the relevant data.
#
# The table is transposed so that each row corresponds to a set
# of data points for one country for one year.
#
# The first two rows are skipped because they are just id fields
# that we are not interested in.
sub process_top_incomes {
  say 'parsing input...';
  my @table = pipeline @_,
    'read_file',
    'decode_json',
    at(1),
    fetch('cell'),
    'transpose',
    curry(\&rest, 2);

  say 'transforming data...';
  my $headers = shift @table;
  map { row_to_hashref($headers, $_) } @table;
}

{
  my $in = 'data/converted.json';
  my $out = 'data/transformed.json';

  if (-f $out) { unlink $out }

  write_file $out, JSON::XS->new->utf8->pretty(1)->encode([ process_top_incomes($in) ]);
}